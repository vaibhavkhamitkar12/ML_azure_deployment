{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "c2a5932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the base libraries for the EDA\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "f59346db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from azureml.core import Run\n",
    "run = Run.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "cffc0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the csv dataset into the pandas dataframe(data)\n",
    "data = pd.read_csv('./creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "ea7ea276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority class instances\n",
    "majority_class = data[data['Class'] == 0]  # Valid transactions\n",
    "minority_class = data[data['Class'] == 1]  # Fraud transactions\n",
    "\n",
    "# Undersample the majority class\n",
    "undersampled_majority_class = resample(majority_class,\n",
    "                                       replace=False,\n",
    "                                       n_samples=len(minority_class),\n",
    "                                       random_state=42)\n",
    "\n",
    "# Combine the minority class DataFrame with the undersampled majority class DataFrame\n",
    "undersampled_data = pd.concat([undersampled_majority_class, minority_class])\n",
    "\n",
    "# Shuffle the undersampled DataFrame\n",
    "data = undersampled_data.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "55370a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "data = data.drop(['Amount', 'Time'], axis=1).assign(scaled_amount=sc.fit_transform(data['Amount'].values.reshape(-1, 1)),scaled_time=sc.fit_transform(data['Time'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "37437d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data.columns[:28])\n",
    "def get_thr_min_max(df, var):\n",
    "    \n",
    "    p25 = df[var].quantile(0.25)\n",
    "    p75 = df[var].quantile(0.75)\n",
    "    iqr = p75-p25\n",
    "\n",
    "    thr_min = p25-1.5*iqr\n",
    "    thr_max = p75+1.5*iqr\n",
    "    \n",
    "    return thr_min, thr_max\n",
    "\n",
    "def outlier_treatment_iqr(val,thr_min,thr_max):\n",
    "    \n",
    "    if val>thr_max:\n",
    "        return thr_max\n",
    "\n",
    "    elif val<thr_min:\n",
    "        return thr_min\n",
    "    \n",
    "    else:\n",
    "        return val\n",
    "for i in features:\n",
    "    thr_min, thr_max = get_thr_min_max(df=data, var= i)\n",
    "    data[i] = data[i].apply(lambda x: outlier_treatment_iqr(x, thr_min, thr_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "2e5c7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop(['Class'], axis=1)\n",
    "y= data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "dbbb59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "a902a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, roc_curve, classification_report, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5658c676",
   "metadata": {
    "scrolled": True
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric Parameter:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': 100, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(random_state=100), 'n_jobs': None, 'param_grid': {'n_estimators': [100, 200, 500], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1', 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc=RandomForestClassifier( random_state = 100 ) \n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model with the optimal hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "run.log(\"Parameter\",grid_search.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19308056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric Accuracy:\n",
      "0.9391891891891891\n",
      "Attempted to log scalar metric Precison:\n",
      "0.9931506849315068\n",
      "Attempted to log scalar metric Recall:\n",
      "0.8950617283950617\n",
      "Attempted to log scalar metric F1 Score:\n",
      "0.9415584415584416\n"
     ]
    }
   ],
   "source": [
    "run.log(\"Accuracy\",accuracy_score(y_test, Y_pred))\n",
    "run.log(\"Precison\",precision_score(y_test, Y_pred))\n",
    "run.log(\"Recall\",recall_score(y_test, Y_pred))\n",
    "run.log(\"F1 Score\",f1_score(y_test, Y_pred))\n",
    "\n",
    "joblib.dump(grid_search, \"credit_card.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
